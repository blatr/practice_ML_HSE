{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical task. Kernelized k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you will get a brief introduction into K-means clustering, its limitations and kernel-trick "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, install package Pillow and import listed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.cluster import KMeans\n",
    "np.random.seed(20)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great tool which is required for this task is KernelKmeans implementation. Luckily you shouldn't design it by yourselves. Everything you need is just executing next cell to have an opportunity to use it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "\n",
    "class KernelKMeans(BaseEstimator, ClusterMixin):\n",
    "    \"\"\"\n",
    "    Kernel K-means\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    Kernel k-means, Spectral Clustering and Normalized Cuts.\n",
    "    Inderjit S. Dhillon, Yuqiang Guan, Brian Kulis.\n",
    "    KDD 2004.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters=3, max_iter=50, tol=1e-3, random_state=None,\n",
    "                 kernel=\"linear\", gamma=None, degree=3, coef0=1,\n",
    "                 kernel_params=None, verbose=0):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "        self.kernel_params = kernel_params\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    @property\n",
    "    def _pairwise(self):\n",
    "        return self.kernel == \"precomputed\"\n",
    "\n",
    "    def _get_kernel(self, X, Y=None):\n",
    "        if callable(self.kernel):\n",
    "            params = self.kernel_params or {}\n",
    "        else:\n",
    "            params = {\"gamma\": self.gamma,\n",
    "                      \"degree\": self.degree,\n",
    "                      \"coef0\": self.coef0}\n",
    "        return pairwise_kernels(X, Y, metric=self.kernel,\n",
    "                                filter_params=True, **params)\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        K = self._get_kernel(X)\n",
    "\n",
    "        sw = sample_weight if sample_weight else np.ones(n_samples)\n",
    "        self.sample_weight_ = sw\n",
    "\n",
    "        rs = check_random_state(self.random_state)\n",
    "        self.labels_ = rs.randint(self.n_clusters, size=n_samples)\n",
    "\n",
    "        dist = np.zeros((n_samples, self.n_clusters))\n",
    "        self.within_distances_ = np.zeros(self.n_clusters)\n",
    "\n",
    "        for it in range(self.max_iter):\n",
    "            dist.fill(0)\n",
    "            self._compute_dist(K, dist, self.within_distances_,\n",
    "                               update_within=True)\n",
    "            labels_old = self.labels_\n",
    "            self.labels_ = dist.argmin(axis=1)\n",
    "\n",
    "            # Compute the number of samples whose cluster did not change \n",
    "            # since last iteration.\n",
    "            n_same = np.sum((self.labels_ - labels_old) == 0)\n",
    "            if 1 - float(n_same) / n_samples < self.tol:\n",
    "                if self.verbose:\n",
    "                    print (\"Converged at iteration\", it + 1)\n",
    "                break\n",
    "\n",
    "        self.X_fit_ = X\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _compute_dist(self, K, dist, within_distances, update_within):\n",
    "        \"\"\"Compute a n_samples x n_clusters distance matrix using the \n",
    "        kernel trick.\"\"\"\n",
    "        sw = self.sample_weight_\n",
    "\n",
    "        for j in range(self.n_clusters):\n",
    "            mask = self.labels_ == j\n",
    "\n",
    "            if np.sum(mask) == 0:\n",
    "                raise ValueError(\"Empty cluster found, try smaller n_cluster.\")\n",
    "\n",
    "            denom = sw[mask].sum()\n",
    "            denomsq = denom * denom\n",
    "\n",
    "            if update_within:\n",
    "                KK = K[mask][:, mask]  # K[mask, mask] does not work.\n",
    "                dist_j = np.sum(np.outer(sw[mask], sw[mask]) * KK / denomsq)\n",
    "                within_distances[j] = dist_j\n",
    "                dist[:, j] += dist_j\n",
    "            else:\n",
    "                dist[:, j] += within_distances[j]\n",
    "\n",
    "            dist[:, j] -= 2 * np.sum(sw[mask] * K[:, mask], axis=1) / denom\n",
    "\n",
    "    def predict(self, X):\n",
    "        K = self._get_kernel(X, self.X_fit_)\n",
    "        n_samples = X.shape[0]\n",
    "        dist = np.zeros((n_samples, self.n_clusters))\n",
    "        self._compute_dist(K, dist, self.within_distances_,\n",
    "                           update_within=False)\n",
    "        return dist.argmin(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve a typical problem let's generate a synthetic dataset which is called \"blob\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_circles\n",
    "X, y = make_circles(300, factor=.1, noise=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "ax =plt.gca()\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn',linewidth=1.0, edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may see, the dataset consist of 2 classes which are not linearly separable.\n",
    "You may remember that one of the limitation of classical K-Means algorithm is that it doesn't work with such type of data. \n",
    "To prove it execute next cell and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=KMeans(n_clusters=2)\n",
    "clf.fit(X,y)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "ax =plt.gca()\n",
    "ax.scatter(X[:, 0], X[:, 1], c=clf.predict(X), s=50, cmap='autumn',linewidth=1.0, edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Explain in your own words why K-Means doesn't work in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get rid of these limitations let's map our data from R2 space to R3 using custom kernel and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "def plot_3D(elev=30, azim=30, X=X, y=y):\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter3D(X[:, 0], X[:, 1], np.exp(-(X ** (2)).sum(1)), c=y, s=50, cmap='autumn',linewidth=1.0, edgecolor=\"black\")\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('r')\n",
    "\n",
    "interact(plot_3D, elev=(-90, 90), azip=(-180, 180),\n",
    "         X=fixed(X), y=fixed(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Describe our custom kernel and apply it for the 5th point in our dataset (write down the formula for the new dimension and append new point coordinates as an example)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use kernelized k-means and check the results. NB: Unfortunately clustering algorithms are not stable therefore you have to rerun the algorithm until you get the desired result. If you don't get it, change \"KernelKmeans\" to \"KMeans\" and pass init=np.array([[0,0,0],[0,0,1]]) as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = np.exp(-(X ** (2)).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_k=KernelKMeans(n_clusters=2)\n",
    "clf_k.fit(np.append(X,[[x] for x in r],axis=1))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=clf_k.predict((np.append(X,[[x] for x in r],axis=1))), s=80, cmap='viridis',linewidth=1.0, edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Describe the results of the algorithm and explain why does it work now?     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
